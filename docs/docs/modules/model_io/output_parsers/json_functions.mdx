# JSON Functions Output Parser

import CodeBlock from "@theme/CodeBlock";
import JSONFunctions from "@examples/prompts/json_structured_output_parser.ts";
import StreamingJSONFunctions from "@examples/prompts/json_structured_output_parser_streaming.ts";

The JSON Functions Output Parser is a useful tool for parsing structured JSON function responses, such as those from [OpenAI functions](/docs/modules/model_io/models/chat/how_to/function_calling). This parser is particularly useful when you need to extract specific information from complex JSON responses.

Here's how it works:

1. **Output Parser**: You can either pass in a predefined `outputParser`, or the parser will use the default `OutputFunctionsParser`.

2. **Default Behavior**: If the default `OutputFunctionsParser` is used, it extracts the function call from the response generation and applies `JSON.stringify` to it.

3. **ArgsOnly Parameter**: If the `argsOnly` parameter is set to true, the parser will only return the arguments of the function call, without applying `JSON.stringify` to the response.

4. **Response Parsing**: The response from the output parser is then parsed again, and the result is returned.

Let's look at an example:

<CodeBlock language="typescript">{JSONFunctions}</CodeBlock>

In this example, we first define a function schema and instantiate the `ChatOpenAI` class. We then create a runnable by binding the function to the model and piping the output through the `JsonOutputFunctionsParser`. When we invoke the runnable with an input, the response is already parsed thanks to the output parser.

The result will be a JSON object that contains the parsed response from the function call.

## Streaming

This parser is also convenient for parsing functions responses in a streaming fashion. It supports either the aggregated functions response or a [JSON patch](https://jsonpatch.com/) diff:

<CodeBlock language="typescript">{StreamingJSONFunctions}</CodeBlock>
